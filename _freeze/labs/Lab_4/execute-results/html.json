{
  "hash": "ee90a54c2026d2205b90adf4644eb8b2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 4 - Multiple Linear Regression\"\ncategories: \"Lab\"\n---\n\n\n\n\n\n\n## [Introduction]{style=\"color:#4166f5;\"}\n\nMany college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics such as the physical appearance of the instructor. The article titled, ***“Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity”*** by Hamermesh and Parker, found that instructors who are viewed to be better looking receive higher instructional ratings. In this lab, you will analyze the data from this study in order to learn what goes into a positive professor evaluation. You will also use the GGally package for visualization relationships between many variables pairs at once and the broom package to tidy your regression outputs. The goal is to perform model selection in order to isolate the \"most important \"variables.\n\n## [Creating a quarto file]{style=\"color:#4166f5;\"}\n\n-   Create a new Quarto document with the title **Multiple Linear Regression**. Change the output format to **pdf** (note that it is set to html by default). Refer to lab_00_Guide if you don't remember how to create a new quarto file. Save the file as `lab_04`.\n\n-   Note that if you created the file correctly, it should appear under files with a `.qmd` extension(i.e., `lab_04.qmd`). If you do not have this file exactly as described, please **STOP** and make sure you have it done correctly before you proceed.\n\n-   After correctly creating the file, click on `Render` to see the output in pdf format. Note that it may pop up in a new window. This step is just for ensuring that your document created properly and that you are able to generate a `pdf`, the format in which you will submit the your lab.\n\n## [Packages]{style=\"color:#4166f5;\"}\n\nYou will need the following packages for this lab: `openintro`, `tidyverse`, `statsr`, `GGally`, and `broom`. Recall that we have previously installed all these packages. All we need to do is load them into our work space. Use code below:\n\n``` toml\nlibrary(openintro)\nlibrary(tidyverse)\nlibrary(statsr)\nlibrary(broom)\nlibrary(GGally)\n```\n\nBe sure to run the packages code chunk above to ensure that they are all loaded correctly. Remember to use `include=F` option (i.e., `{r, include=F}`) to prevent the code output for loading packages from showing up in your rendered report.\n\n## [Loading (and viewing) Data]{style=\"color:#4166f5;\"}\n\nWe will use a data frame called `evals` contained in the **openintro** package. The data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors’ physical appearance (`bty`). The result is a data frame where each row contains a different course and columns represent variables about the courses and professors.\n\nSince we have already activated `openintro`, we can load the data by running the `data` command. See below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(evals)\n```\n:::\n\n\n\n\nOnce you run the chunk above, you should be able to see a new object called **evals** in the environment area. Click on it to examine the data.\n\nFirst, let us learn more about the data by running the following command in the **console**.\n\n``` toml\n?evals\n```\n\n## [Examining Relationships]{style=\"color:#4166f5;\"}\n\nIt is often useful to examine relationships between variables before using them to run regression models. The most commonly used tool for this are scatter plots. The problem here is that we have several variables and we would have to make several combinations of two. We want to use the `GGally` package to create a scatter plot matrix, that allows us to see the relationships between all the variables in the data set at once. To achieve this, we use the `pairs` function from the `GGally` package as shown below. Notice that we first select the columns of interest:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals|>\n  select(score,rank,gender,ethnicity,language,cls_perc_eval,cls_level,cls_students,cls_credits,bty_avg,cls_credits)|>\n  pairs()\n```\n:::\n\n\n\n\n## [Multiple Linear Regression Modeling]{style=\"color:#4166f5;\"}\n\nWe want to start by creating a full model (we can name it `m_full`) that predicts professor `score` based on the following predictors: `rank`, `gender`, `ethnicity`, `language` (language of the university where they got their degree), `age`, `cls_perc_eval` (proportion of students that filled out evaluations), `cls_students` (number of students in class), `cls_level` (course level), `cls_profs` (number of professors), `cls_credits` (number of credits), and `bty_avg` (average beauty rating). Note that some of these variables are categorical and others are numerical. You can learn more about these variables including how they were measured by checking the documentation (you can run `?evals` in the console).\n\nBefore running the code below, answer the following question:\n\nHow many variables do you expect to be in the multiple regression model? How do you know?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_full <- lm(score ~ rank\n                  + gender \n                  + ethnicity \n                  + language \n                  + age \n                  + cls_perc_eval \n                  + cls_students \n                  + cls_level \n                  + cls_profs \n                  + cls_credits \n                  + bty_avg, data = evals)\ntidy(m_full)\n```\n:::\n\n\n\n\n**Questions:**\n\n-   How many variables are in the model? Is this what you expected?\n\n-   Interpret the coefficient associated with the `ethnicity` variable.\n\n## [Model Pruning]{style=\"color:#4166f5;\"}\n\nThe above model is called a **full model** because it contains all possible predictors. The full model is not always the best. We can improve on this model by dropping certain predictors that are not ***adding value*** to the model. We are going to use one of the **step-wise selection** methods (backward elimination) to prune the above model in order to improve it. We are trying to increase the adjusted $R^2$.\n\n### [Step 1]{style=\"color:#4166f5;\"}\n\nWe will start with the **full model** (`m_full`) and its adjusted $R^2$. Run the `glance` function to check the adjusted $R^2$ of the model above (m_full). Interpret the value in context.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(m_full)\n```\n:::\n\n\n\n\nThe output shows that the adjusted $R^2$ is $14.12\\%$. We use this number as our baseline and drop predictors **one at a time**, each time checking on the improvement in the adjusted $R^2$. Our new model will be one that leads to the highest improvement in the adjusted $R^2$.\n\nLet us start by dropping `rank` (we can call the model without rank `rm_rank` (meaning remove rank). We also run the `glance` command to get the adjusted $R^2$ for the model. See the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_rank <- lm(score ~ gender \n                    + ethnicity \n                    + language \n                    + age \n                    + cls_perc_eval \n                    + cls_students \n                    + cls_level \n                    + cls_profs \n                    + cls_credits \n                    + bty_avg, data = evals)\nglance(rm_rank)\n```\n:::\n\n\n\n\nDropping rank from the model gives an adjusted $R^2$ value of 14.18%. This is an improvement of 0.06 (14.18 - 14.12).\n\nNext, we want to check the effect of dropping `gender` instead. See below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_gender <- lm(score ~ rank \n                      + ethnicity \n                      + language \n                      + age \n                      + cls_perc_eval \n                      + cls_students \n                      + cls_level \n                      + cls_profs \n                      + cls_credits \n                      + bty_avg, data = evals)\n#tidy(rm_gender)\nglance(rm_gender)\n```\n:::\n\n\n\n\nNote that dropping gender leads to a reduced adjusted $R^2$. So, this may not be a good idea at this stage.\n\nNext, let us drop `ethnicity` and see what happens:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_ethnicity <- lm(score ~ rank\n                          + gender \n                          + language \n                          + age \n                          + cls_perc_eval \n                          + cls_students \n                          + cls_level \n                          + cls_profs \n                          + cls_credits \n                          + bty_avg, data = evals)\nglance(rm_ethnicity)\n```\n:::\n\n\n\n\nWhat can you comment about the effect of dropping `ethnicity`?\n\nNext, drop `language`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_language <- lm(score ~ rank\n                        + ethnicity\n                        + gender \n                        + age \n                        + cls_perc_eval \n                        + cls_students \n                        + cls_level \n                        + cls_profs \n                        + cls_credits \n                        + bty_avg, data = evals)\n#tidy(rm_language)\nglance(rm_language)\n```\n:::\n\n\n\n\nWhat is the effect of dropping language?\n\nNext, drop `age`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_age <- lm(score ~ rank\n                  + ethnicity\n                  + gender\n                  + language\n                  + cls_perc_eval \n                  + cls_students \n                  + cls_level \n                  + cls_profs \n                  + cls_credits \n                  + bty_avg, data = evals)\nglance(rm_age)\n```\n:::\n\n\n\n\nComment on the effect of dropping `age`:\n\nNext, drop `cls_perc_eval` (i.e., proportion of students that filled out evaluations):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_perc_eval <- lm(score ~ rank\n                              + ethnicity\n                              + age\n                              + gender\n                              + language\n                              + cls_students \n                              + cls_level \n                              + cls_profs \n                              + cls_credits \n                              + bty_avg, data = evals)\nglance(rm_cls_perc_eval)\n```\n:::\n\n\n\n\nComment appropriately.\n\nNext, drop `cls_students` (class size):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_students <- lm(score ~ rank\n                            + ethnicity\n                            + age\n                            + gender\n                            + cls_perc_eval\n                            + language\n                            + cls_level \n                            + cls_profs \n                            + cls_credits \n                            + bty_avg, data = evals)\nglance(rm_cls_students)\n```\n:::\n\n\n\n\nComment on the effect of dropping class size.\n\nNext, drop `cls_level` (course level):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_level <- lm(score ~ rank\n                          + ethnicity\n                          + age\n                          + gender\n                          + cls_students\n                          + cls_perc_eval\n                          + language\n                          + cls_profs \n                          + cls_credits \n                          + bty_avg, data = evals)\nglance(rm_cls_level)\n```\n:::\n\n\n\n\nDoes dropping course level lead to an increase in the adjusted $R^2$. if so, by how much?\n\n<!-- 14.29-14.12=.17-->\n\nWe are almost done. Next, drop `cls_profs` (number of professors):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_profs <- lm(score ~ rank\n                          + ethnicity\n                          + age\n                          + gender\n                          + cls_students\n                          + cls_level\n                          + cls_perc_eval\n                          + language\n                          + cls_credits \n                          + bty_avg, data = evals)\nglance(rm_cls_profs)\n```\n:::\n\n\n\n\nDoes dropping `cls_profs` lead to an increase in adjusted $R^2$? By how much?\n\n<!-- 14.3-14.12=.18-->\n\nNext, drop `cls_credits` (i.e., number of credits):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_credits <- lm(score ~ rank\n                          + ethnicity\n                          + age\n                          + gender\n                          + cls_students\n                          + cls_level\n                          + cls_perc_eval\n                          + language\n                          + cls_profs\n                          + bty_avg, data = evals)\nglance(rm_cls_credits)\n```\n:::\n\n\n\n\nComment on the effect of dropping `cls_credits`.\n\nFinally, drop `bty_avg` (i.e., average beauty score):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_bty_avg <- lm(score ~ rank\n                        + ethnicity\n                        + age\n                        + gender\n                        + cls_students\n                        + cls_level\n                        + cls_perc_eval\n                        +cls_credits\n                        + language\n                        + cls_profs, data = evals)\nglance(rm_bty_avg)\n```\n:::\n\n\n\n\nAs you have seen, dropping `class_profs` leads to the most improvement to the model (the adjusted $R^2$ improves from 14.12% to 14.31%). So, we create a new model (and name it `m_prunned_1`) without `cls_profs` and check its adjusted $R^2$. See code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_prunned_1 <- lm(score ~ rank \n                        + gender \n                        + ethnicity \n                        + language \n                        + age \n                        + cls_perc_eval \n                        + cls_students \n                        + cls_level \n                        + cls_credits \n                        + bty_avg, data = evals)\n#tidy(m_prunned_1)\nglance(m_prunned_1)\n```\n:::\n\n\n\n\nThe new adjusted $R^2$ is $14.31\\%$. We will repeat the process above using 14.31% as the base value. We drop variables one at a time.\n\n### [Step 2]{style=\"color:#4166f5;\"}\n\nWe repeat the process above using `m_prunned_1` as the baseline. Remember, its adjusted $R^2$ is $14.31\\%$.\n\nFirst, drop gender:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_gender <- lm(score ~ rank \n                      + ethnicity \n                      + language \n                      + age \n                      + cls_perc_eval \n                      + cls_students \n                      + cls_level \n                      + cls_credits \n                      + bty_avg, data = evals)\n#tidy(rm_gender)\nglance(rm_gender)\n```\n:::\n\n\n\n\nNo improvement when we drop gender from the model. Next, let us remove rank:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_rank <- lm(score ~ gender \n                    + ethnicity \n                    + language \n                    + age \n                    + cls_perc_eval \n                    + cls_students \n                    + cls_level \n                    + cls_credits \n                    + bty_avg, data = evals)\n#tidy(rm_rank)\nglance(rm_rank)\n```\n:::\n\n\n\n\nImproved: 14.36-14.31=0.05\n\nNext, remove ethnicity,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_ethnicity <- lm(score ~ rank \n                        + gender \n                        + language \n                        + age \n                        + cls_perc_eval \n                        + cls_students \n                        + cls_level \n                        + cls_credits \n                        + bty_avg, data = evals)\n#tidy(rm_ethnicity)\nglance(rm_ethnicity)\n```\n:::\n\n\n\n\nNext, remove `language`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_language <- lm(score ~ rank \n                        + gender \n                        + ethnicity \n                        + age \n                        + cls_perc_eval \n                        + cls_students \n                        + cls_level \n                        + cls_credits \n                        + bty_avg, data = evals)\n#tidy(rm_language)\nglance(rm_language)\n```\n:::\n\n\n\n\nNo improvement.\n\nNext, remove age:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_age <- lm(score ~ rank \n                  + gender \n                  + ethnicity \n                  + language \n                  + cls_perc_eval \n                  + cls_students \n                  + cls_level \n                  + cls_credits \n                  + bty_avg, data = evals)\n#tidy(rm_age)\nglance(rm_age)\n```\n:::\n\n\n\n\nNo improvement.\n\nNext, remove `cls_perc_eval`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_per_eval <- lm(score ~ rank \n                            + gender \n                            + ethnicity \n                            + language \n                            + age \n                            + cls_students \n                            + cls_level \n                            + cls_credits \n                            + bty_avg, data = evals)\n#tidy(rm_cls_per_eval)\nglance(rm_cls_per_eval)\n```\n:::\n\n\n\n\nNo improvement.\n\nNext, remove `cls_students`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_st <- lm(score ~ rank \n                      + gender \n                      + ethnicity \n                      + language \n                      + age \n                      + cls_perc_eval \n                      + cls_level \n                      + cls_credits \n                      + bty_avg, data = evals)\n#tidy(rm_cls_st)\nglance(rm_cls_st)\n```\n:::\n\n\n\n\nNo improvement.\n\nNext, remove `cls_level`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_level <- lm(score ~ rank \n                          + gender \n                          + ethnicity \n                          + language \n                          + age \n                          + cls_perc_eval \n                          + cls_students \n                          + cls_credits \n                          + bty_avg, data = evals)\n#tidy(rm_cls_level)\nglance(rm_cls_level)\n```\n:::\n\n\n\n\nModel improves by: 14.47-14.31=.16%\n\nNext, remove `cls_credits`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_cls_credits <- lm(score ~ rank \n                          + gender \n                          + ethnicity \n                          + language \n                          + age \n                          + cls_perc_eval \n                          + cls_students \n                          + cls_level \n                          + bty_avg, data = evals)\n#tidy(rm_cls_credits)\nglance(rm_cls_credits)\n```\n:::\n\n\n\n\nNo improvement.\n\nFinally, we remove `bty_avg`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_bty_avg <- lm(score ~ rank \n                      + gender \n                      + ethnicity \n                      + language \n                      + age \n                      + cls_perc_eval \n                      + cls_students \n                      + cls_level \n                      + cls_credits, data = evals)\n#tidy(rm_bty_avg)\nglance(rm_bty_avg)\n```\n:::\n\n\n\n\nNo improvement when you drop `bty_avg.`\n\nWe notice that removing `cls_level` leads to the most improvement in the adjusted $R^2$ of .16 ($14.47-14.31=.16$). So, our new improved model (call it `m_prunned_2`) is:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_prunned_2 <- lm(score ~ rank \n                        + gender \n                        + ethnicity \n                        + language \n                        + age \n                        + cls_perc_eval \n                        + cls_students \n                        + cls_credits \n                        + bty_avg, data = evals)\n#tidy(rm_prunned_2)\nglance(m_prunned_2)\n```\n:::\n\n\n\n\n### [Step 3]{style=\"color:#4166f5;\"}\n\nWe use the model from step 2 above along with its adjusted $R^2$ (14.48%) as the baseline for step 3. The rest of the work is left as an exercise.\n\n## [Exercises]{style=\"color:#4166f5;\"}\n\n1.  ***(8 pts)*** In class, we began the backward elimination method (based on adjusted R-squared) for model selection. Complete the steps to come up with the best model. You do not need to show all steps in your answer, just the output for the final model. Also, write out the linear model for predicting score based on the final model you settle on.\n\n2.  ***(4 pts)*** Based on your final model, describe the characteristics of a professor and course at University of Texas at Austin that would be associated with a high evaluation score. What characteristics are associated with low course evaluation scores?\n\n3.  ***(4 pts)*** Pick one slope for a numerical variable in your model and one for a categorical variable and interpret them in context.\n\n4.  ***(4 pts)*** Would you be comfortable generalizing your conclusions to professors generally (at any university)? Why or why not?\n\n## Submission\n\nOnce you are finished with the lab, you will submit your final PDF document to Canvas.\n\n::: callout-warning\nBefore you wrap up the assignment, make sure all questions are numbered appropriately. Delete any code chunks that were not used.\n\nYou must turn in a PDF file to the Canvas page by the submission deadline to be considered \"on time\".\n:::\n\n::: callout-important\n## Checklist\n\nMake sure you have:\n\n-   attempted all questions\n-   rendered your Quarto document to PDF\n-   uploaded your PDF to Canvas\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}